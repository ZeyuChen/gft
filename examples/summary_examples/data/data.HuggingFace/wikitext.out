dataset: wikitext	dataset: wikitext	downloads: 134585	likes: 9	PWC: https://paperswithcode.com/dataset/wikitext-2
dataset: wikitext,wikitext-103-v1	splits: test: 4358 rows, train: 1801350 rows, val: 3760 rows
dataset: wikitext,wikitext-103-v1	split: train	columns: text
dataset: wikitext,wikitext-2-v1	splits: test: 4358 rows, train: 36718 rows, val: 3760 rows
dataset: wikitext,wikitext-2-v1	split: train	columns: text
dataset: wikitext,wikitext-103-raw-v1	splits: test: 4358 rows, train: 1801350 rows, val: 3760 rows
dataset: wikitext,wikitext-103-raw-v1	split: train	columns: text
dataset: wikitext,wikitext-2-raw-v1	splits: test: 4358 rows, train: 36718 rows, val: 3760 rows
dataset: wikitext,wikitext-2-raw-v1	split: train	columns: text
dataset: wikitext --> 10 models
dataset: wikitext	model: markussagen/xlm-roberta-longformer-base-4096	downloads: 1959	likes: 8	task: fill-mask
dataset: wikitext	model: Peltarion/xlm-roberta-longformer-base-4096	downloads: 390	likes: 1	task: fill-mask
dataset: wikitext	model: saghar/xtremedistil-l6-h384-uncased-finetuned-wikitext103	downloads: 69	likes: 0	task: fill-mask
dataset: wikitext	model: saghar/TinyBERT_General_6L_768D-finetuned-wikitext103	downloads: 58	likes: 0	task: fill-mask
dataset: wikitext	model: saghar/MiniLMv2-L6-H384-distilled-from-RoBERTa-Large-finetuned-wikitext103	downloads: 53	likes: 0	task: fill-mask
dataset: wikitext	model: saghar/xtremedistil-l12-h384-uncased-finetuned-wikitext103	downloads: 50	likes: 0	task: fill-mask
dataset: wikitext	model: saghar/MiniLMv2-L6-H768-distilled-from-RoBERTa-Large-finetuned-wikitext103	downloads: 42	likes: 0	task: fill-mask
dataset: wikitext	model: Graphcore/gpt2-wikitext-103	downloads: 35	likes: 0	task: text-generation
dataset: wikitext	model: mikaelsouza/msft-regular-model	downloads: 17	likes: 1	task: text-generation
dataset: wikitext	model: saghar/TinyBERT_L-4_H-312_v2-finetuned-wikitext103	downloads: 13	likes: 0	task: fill-mask
# found: 11541 matches; truncating to 10
task: None --> 10 models
task: None	model: SpanBERT/spanbert-large-cased	downloads: 0	likes: 0	task: None
task: None	model: microsoft/layoutlmv2-base-uncased	downloads: 0	likes: 0	task: None
task: None	model: microsoft/layoutlm-base-uncased	downloads: 0	likes: 0	task: None
task: None	model: microsoft/deberta-base	downloads: 0	likes: 0	task: None
task: None	model: facebook/dpr-ctx_encoder-single-nq-base	downloads: 0	likes: 0	task: None
task: None	model: dmis-lab/biobert-base-cased-v1.1	downloads: 0	likes: 0	task: None
task: None	model: distilbert-base-cased	downloads: 0	likes: 0	task: None
task: None	model: hfl/chinese-electra-180g-base-discriminator	downloads: 0	likes: 0	task: None
task: None	model: google/bigbird-roberta-base	downloads: 0	likes: 0	task: None
task: None	model: microsoft/deberta-v3-base	downloads: 0	likes: 0	task: None
